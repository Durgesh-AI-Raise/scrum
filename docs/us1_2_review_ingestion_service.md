# Sprint Backlog - User Story 1.2: Develop service to ingest new review data

## Implementation Plan
*   Create a dedicated microservice, `ReviewIngestionService`, responsible for receiving new product review data.
*   Expose a RESTful API endpoint (e.g., `/reviews/ingest`) to accept `POST` requests containing review data.
*   Implement input validation to ensure the integrity and completeness of the incoming review data (e.g., check for required fields, validate rating range, timestamp format).
*   Persist the validated review data into a primary data store.
*   Publish an event to a message queue (e.g., Kafka topic `review_ingested_events`) upon successful ingestion, containing the new review's essential details for downstream processing.

## Data Models
```python
# Review Data Model (Conceptual - for Storage)
class Review:
    review_id: str         # Unique identifier for the review
    product_id: str        # Identifier for the product being reviewed
    user_id: str           # Identifier for the user who submitted the review
    rating: int            # Rating given by the user (e.g., 1-5 stars)
    review_text: str       # The actual text content of the review
    submission_timestamp: datetime # Timestamp when the review was submitted
    # user_creation_timestamp: datetime # Potentially stored for rules engine
```

## Architecture
*   **ReviewIngestionService:** A Python-based microservice (e.g., using Flask or FastAPI).
*   **API Gateway (Implicit):** Assumed to route requests to `/reviews/ingest`.
*   **Data Store:** PostgreSQL (or similar relational database) for durable storage of raw review data.
*   **Message Queue:** Apache Kafka or RabbitMQ for asynchronous, decoupled communication.

## Assumptions/Technical Decisions
*   Reviews will be submitted as JSON payloads.
*   Message queue provides resilience and allows for scalable, asynchronous processing.
*   `review_id` is assumed to be unique and provided by the client, or generated by the ingestion service if not provided.
*   Error responses will follow standard HTTP status codes (e.g., 400 for bad request, 500 for internal errors).

## Code Snippets/Pseudocode (`app/services/review_ingestion_service.py`)
```python
from flask import Flask, request, jsonify
from datetime import datetime
import json # For serializing to JSON string if needed for MQ

app = Flask(__name__)

# Placeholder for a database client and message queue producer
# from some_db_library import ReviewRepository
# from some_mq_library import MessageQueueProducer

# review_repo = ReviewRepository()
# mq_producer = MessageQueueProducer('review_ingested_events')

@app.route('/reviews/ingest', methods=['POST'])
def ingest_review():
    data = request.get_json()

    # 1. Input Validation
    required_fields = ['review_id', 'product_id', 'user_id', 'rating', 'review_text', 'submission_timestamp']
    if not all(field in data and data[field] is not None for field in required_fields):
        return jsonify({"error": "Missing or null value for one or more required fields."}), 400

    try:
        # Validate rating as integer between 1 and 5
        data['rating'] = int(data['rating'])
        if not (1 <= data['rating'] <= 5):
            return jsonify({"error": "Rating must be an integer between 1 and 5."}), 400

        # Validate timestamp format
        data['submission_timestamp'] = datetime.fromisoformat(data['submission_timestamp'].replace('Z', '+00:00'))
    except (ValueError, TypeError) as e:
        return jsonify({"error": f"Invalid data format for rating or timestamp: {e}"}), 400

    # Optional: Add user creation timestamp if available from a User service
    # user_creation_timestamp = fetch_user_creation_timestamp(data['user_id']) # Placeholder
    # data['user_creation_timestamp'] = user_creation_timestamp.isoformat() if user_creation_timestamp else None

    # 2. Store in Database (Pseudocode)
    # try:
    #     review_repo.save(data) # Assumes data dict maps directly to Review model
    #     print(f"Successfully stored review: {data['review_id']}")
    # except Exception as e:
    #     print(f"Database error storing review {data['review_id']}: {e}")
    #     return jsonify({"error": "Failed to store review in database."}), 500
    print(f"Simulating DB save for review: {data['review_id']}")


    # 3. Publish Event to Message Queue (Pseudocode)
    event_payload = {
        "review_id": data['review_id'],
        "product_id": data['product_id'],
        "user_id": data['user_id'],
        "rating": data['rating'],
        "review_text_length": len(data['review_text']), # Avoid sending full text if not needed
        "submission_timestamp": data['submission_timestamp'].isoformat(),
        # "user_creation_timestamp": data.get('user_creation_timestamp')
    }
    # try:
    #     mq_producer.publish(event_payload)
    #     print(f"Published review ingested event for: {data['review_id']}")
    # except Exception as e:
    #     print(f"Message queue error for review {data['review_id']}: {e}")
    #     # Depending on criticality, might still return 201 but log prominently
    #     return jsonify({"error": "Review stored, but failed to publish event."}), 500
    print(f"Simulating MQ publish for review: {data['review_id']}")


    return jsonify({"message": "Review ingested successfully.", "review_id": data['review_id']}), 201

if __name__ == '__main__':
    app.run(debug=True, port=5000)
```