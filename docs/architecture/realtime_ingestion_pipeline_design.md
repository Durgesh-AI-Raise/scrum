# Real-time Review Data Ingestion Pipeline Design

## 1. Architecture Overview

The real-time review data ingestion pipeline is designed to be scalable, fault-tolerant, and enable immediate processing of new review submissions for abuse detection.

```
[Client (Web/Mobile)] --> [API Gateway/Load Balancer] --> [Ingestion Service (Flask/FastAPI)]
    |                                                                  |
    v                                                                  v
[Kafka Cluster] --------------------------------------------------> [Validation Service (Kafka Consumer)]
    ^   |                                                                  |
    |   | (raw_reviews topic)                                                | (validated_reviews topic)
    |   ---------------------------------------------------------------------> [ML Models (Consumers)]
    |                                                                          |
    | (dead_letter_queue_reviews topic)                                        v
    -----------------------------------------------------------------------> [Flagged Data Storage]
```

## 2. Key Components

*   **Client:** Web or mobile applications submitting user reviews.
*   **API Gateway/Load Balancer:**
    *   Acts as the single entry point for all review submission requests.
    *   Handles request routing, potentially rate limiting, authentication, and SSL termination.
    *   Ensures high availability and load distribution to the Ingestion Service.
*   **Ingestion Service (Python Flask/FastAPI):**
    *   A microservice responsible for receiving review data from the API Gateway via a RESTful endpoint.
    *   Adds crucial metadata to each review, such as a unique `review_id` (UUID) and a `timestamp` (ISO 8601 UTC).
    *   Publishes the raw, unvalidated review data as JSON messages to the `raw_reviews` Kafka topic.
*   **Kafka Cluster:**
    *   Serves as the central, high-throughput, distributed streaming platform.
    *   **`raw_reviews` Topic:** Stores all incoming review data immediately after ingestion. This topic acts as a buffer and ensures data durability before further processing.
    *   **`validated_reviews` Topic:** Stores review data that has successfully passed initial schema and basic content validation. This is the primary input for downstream ML services.
    *   **`dead_letter_queue_reviews` Topic:** A dedicated topic for messages that fail validation or other processing steps. This prevents data loss and allows for asynchronous investigation and re-processing of malformed data.
*   **Validation Service (Kafka Consumer):**
    *   A microservice that consumes messages from the `raw_reviews` topic.
    *   Performs schema validation, data type checks, and basic content validation (e.g., ensuring `rating` is within a valid range, `review_text` is not empty).
    *   Publishes valid reviews to the `validated_reviews` topic.
    *   Publishes invalid reviews, along with error details, to the `dead_letter_queue_reviews` topic.
*   **ML Models (Kafka Consumers):**
    *   Multiple microservices (e.g., "Anomalous Review Pattern Detection Model," "Suspicious Account Detection Model") that consume from the `validated_reviews` topic.
    *   Perform real-time inference to identify suspicious reviews or accounts.
    *   Publish flagged reviews/accounts to the `flagged_reviews_stream` topic (or directly to Flagged Data Storage, depending on design).
*   **Flagged Data Storage:**
    *   A dedicated database (e.g., PostgreSQL, MongoDB) for securely storing flagged reviews, their associated metadata, flagging reasons, and investigation status.
    *   Accessible by Trust & Safety teams for investigation and by ML engineers for model retraining.

## 3. Data Model: Review Event

The following JSON structure represents a review event as it flows through the Kafka topics. Additional metadata is added at different stages.

```json
{
    "review_id": "string (UUID)",          // Unique identifier for the review, generated by Ingestion Service.
    "product_id": "string",                // ID of the product being reviewed.
    "user_id": "string",                   // ID of the user submitting the review.
    "review_text": "string",               // The actual text content of the review.
    "rating": "integer (1-5)",             // Rating given by the user.
    "timestamp": "string (ISO 8601 UTC)",  // Timestamp of review submission, generated by Ingestion Service.
    "device_info": "string (optional)",    // e.g., 'mobile', 'web', browser agent string.
    "ip_address": "string (optional)",     // IP address of the reviewer (anonymized/hashed if privacy concerns).
    "location_data": "string (optional)",  // Geographic location data (derived from IP or client).
    "is_flagged": "boolean",               // Flag indicating if the review is suspicious (default: false, updated by ML/rules).
    "flag_reason": "array of strings"      // Reasons for flagging (e.g., ['anomalous_pattern', 'suspicious_account', 'new_account_suspicious']).
}
```

## 4. Assumptions and Technical Decisions

*   **Messaging System:** Kafka is chosen for its high throughput, fault tolerance, horizontal scalability, and ordered message delivery. It enables asynchronous processing and decoupling of services.
*   **API Framework:** Python with Flask/FastAPI for the Ingestion Service endpoint due to rapid development capabilities and compatibility with the existing Python ecosystem for ML.
*   **Data Format:** JSON is used for message payloads across Kafka topics due to its universality, readability, and ease of parsing in various programming languages.
*   **Scalability:** The architecture is designed for horizontal scalability at each layer (API Gateway, Ingestion Service, Kafka, Kafka Consumers).
*   **Error Handling:** A dedicated Dead Letter Queue (`dead_letter_queue_reviews`) is implemented to gracefully handle malformed or invalid messages, preventing data loss and allowing for asynchronous error investigation and resolution.
*   **Review ID Generation:** A unique UUID is generated for each review upon its initial ingestion to ensure immutable traceability throughout the entire pipeline.
*   **Timestamp Standard:** All timestamps will be in UTC and adhere to the ISO 8601 format for consistency and ease of parsing across different systems.
*   **Cloud Agnostic (Initial):** While components like Kafka are often managed services in cloud environments, the design aims to be initially adaptable to various cloud providers or on-premise deployments.
*   **Security:** API Gateway will enforce authentication. Data in transit (Kafka) will be encrypted, and data at rest (Flagged Data Storage) will be encrypted. Access controls will be strictly enforced.
